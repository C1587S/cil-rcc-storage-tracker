# Storage Analytics Backend

FastAPI backend for querying and analyzing storage snapshots generated by the Rust scanner. Uses DuckDB for efficient analytical queries over Parquet files.

## Features

- Fast OLAP queries with DuckDB on Parquet files
- RESTful API with OpenAPI documentation
- Environment auto-detection (cluster vs local paths)
- Advanced search with regex and glob patterns
- Folder analytics and hierarchical breakdown
- Heavy files and file type distribution analysis

## Tech Stack

- FastAPI - Modern async web framework
- DuckDB - Embedded analytical database
- Polars - High-performance DataFrame library
- PyArrow - Apache Arrow integration
- Uvicorn - ASGI server

## Quick Start

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Start development server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at http://localhost:8000

## Project Structure

```
backend/
├── app/
│   ├── main.py                # FastAPI application entry
│   ├── config.py              # Configuration management
│   ├── database/              # Database layer (DuckDB client)
│   ├── models/                # Pydantic models
│   ├── routers/               # API endpoints
│   └── services/              # Business logic
├── scripts/                   # Data processing scripts
│   ├── import_snapshot.py
│   ├── create_test_snapshot.py
│   ├── optimize_snapshot.py
│   └── check_environment.py
├── requirements.txt           # Production dependencies
└── README.md                  # This file
```

## API Documentation

Once the server is running:

- Interactive docs: http://localhost:8000/docs
- Alternative docs: http://localhost:8000/redoc
- OpenAPI JSON: http://localhost:8000/openapi.json

## Key API Endpoints

### Snapshots
- `GET /api/snapshots` - List all available snapshots
- `GET /api/snapshots/{date}` - Get specific snapshot details

### Folders
- `GET /api/folders/{path}?snapshot=date` - Get folder breakdown
- `GET /api/folders/{path}/tree?snapshot=date` - Get folder tree structure

### Analytics
- `GET /api/analytics/heavy-files?snapshot=date` - Largest files
- `GET /api/analytics/distribution?snapshot=date` - Size and type distribution

### Search
- `GET /api/search?q=pattern&snapshot=date` - Search files by pattern

## Configuration

Configuration is managed through environment variables in `.env`:

```bash
# Database paths
DUCKDB_PATH="data/storage_analytics.duckdb"
SNAPSHOTS_PATH="data/snapshots"

# Query limits
DEFAULT_SEARCH_LIMIT=1000
MAX_SEARCH_LIMIT=10000

# CORS (automatically configured for localhost)
# CORS_ORIGINS=["http://localhost:3000","http://localhost:3001"]

# Logging
LOG_LEVEL="INFO"
```

## Data Directory Structure

The backend expects Parquet snapshots in this structure:

```
backend/data/
└── snapshots/
    ├── 2025-12-15/
    │   ├── cil.parquet
    │   ├── battuta_shares.parquet
    │   └── gcp.parquet
    └── 2025-12-20/
        └── ...
```

## Data Processing Scripts

### Import a snapshot

Import aggregated Parquet files from the scanner:

```bash
python scripts/import_snapshot.py <source_directory> <snapshot_date>
```

This script will:
1. Copy Parquet files to `data/snapshots/<snapshot_date>/`
2. Validate schema and file integrity
3. Automatically run optimization (creates materialized tables for performance)

Note: The source directory should contain the aggregated Parquet file(s). Use the scanner's `aggregate` command to consolidate chunk files before importing.

### Optimize snapshot performance

For existing snapshots or if automatic optimization failed:

```bash
python scripts/optimize_snapshot.py <snapshot_date>
```

This creates materialized tables that dramatically improve query performance for large snapshots.

The optimization process:
- Creates directory hierarchy table (critical for performance)
- Materializes snapshot summaries, file type breakdowns, heavy files
- Creates indexes on frequently queried columns

Note: This is CRITICAL for large snapshots (1M+ files). The `import_snapshot.py` script now runs this automatically.

### Create test data

```bash
python scripts/create_test_snapshot.py
```

### Check environment

```bash
python scripts/check_environment.py
```

## Environment Auto-Detection

The backend automatically detects whether it's running on the cluster or locally:

- Cluster: Uses `/project/cil` paths
- Local Mac: Uses `/Volumes/cil` paths

This is configured in `app/config.py` and requires no manual intervention.

## Development

### Running Tests

```bash
pytest tests/ -v
```

### Code Quality

```bash
# Format code
black app/ tests/

# Lint code
ruff check app/ tests/

# Type checking
mypy app/
```

## Troubleshooting

### "No snapshots found"

Ensure Parquet files exist in the `SNAPSHOTS_PATH` directory with the correct structure.

### Query timeout

Increase `QUERY_TIMEOUT` in configuration or run the optimize script to materialize views.

### Memory issues

Adjust DuckDB memory limit in `app/database/duckdb_client.py`:
```python
self.conn.execute("SET memory_limit = '8GB'")
```

---

For more information, see the main project [README](../README.md).

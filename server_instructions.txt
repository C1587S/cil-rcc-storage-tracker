========================================
RCC STORAGE TRACKER – FULL SETUP STEPS
========================================

# 0) Connect to the VM
ssh root@<PUBLIC_IP>

----------------------------------------
# 1) Install Docker (one time only)
----------------------------------------

apt update
apt install -y docker.io docker-compose
systemctl enable docker
systemctl start docker

# Verify installation
docker --version
docker compose version

----------------------------------------
# 2) Clone the repository
----------------------------------------

cd /root
git clone https://github.com/C1587S/cil-rcc-storage-tracker.git
cd cil-rcc-storage-tracker

----------------------------------------
# 3) Copy and unzip scan data
----------------------------------------

# Assume the zip file is in /root
ls
# Expect: cil_scans.zip

unzip cil_scans.zip

# Zip creates a deep directory tree; move it
mv project/cil/home_dirs/rcc/cil_scans /root/

# Move scans into the repo
mv /root/cil_scans /root/cil-rcc-storage-tracker/

# Verify structure
ls cil_scans
# battuta_shares gcp home_dirs kupe_shares norgay sacagawea_shares ...

----------------------------------------
# 4) FULL RESET – CLEAN START (IMPORTANT)
----------------------------------------

# This completely deletes ClickHouse data and state
# Use this whenever you want to start from zero

docker compose down -v
docker volume prune -f

# Rebuild images (important if Python scripts changed)
docker compose build --no-cache

# Start only ClickHouse first
docker compose up -d clickhouse

# Wait until ClickHouse is healthy
docker compose ps

----------------------------------------
# 5) Initialize database schema
----------------------------------------

# Creates database, tables, materialized views
docker compose up clickhouse-init

# Verify tables exist
docker compose exec clickhouse clickhouse-client --query "
SHOW TABLES FROM filesystem
"

----------------------------------------
# 6) IMPORT DATA – DIRECTORY BY DIRECTORY
----------------------------------------

# IMPORTANT RULES:
# - First import CLEARS the snapshot
# - All following imports MUST use --no-clear
# - Run directories ONE BY ONE

# 6.1) First import (example: gcp)
docker compose run --rm importer \
python scripts/import_snapshot.py /scans/home_dirs/2025-12-27

# 6.2) Remaining directories
docker compose run --rm importer \
python scripts/import_snapshot.py /scans/battuta_shares/2025-12-27 --no-clear

docker compose run --rm importer \
python scripts/import_snapshot.py /scans/battuta-shares-S3-archive/2025-12-27 --no-clear

docker compose run --rm importer \
python scripts/import_snapshot.py /scans/gcp/2025-12-27 --no-clear

docker compose run --rm importer \
python scripts/import_snapshot.py /scans/kupe_shares/2025-12-27 --no-clear

docker compose run --rm importer \
python scripts/import_snapshot.py /scans/norgay/2025-12-27 --no-clear

docker compose run --rm importer \
python scripts/import_snapshot.py /scans/sacagawea_shares/2025-12-27 --no-clear

----------------------------------------
# 7) Verify that all data was imported
----------------------------------------

docker compose exec clickhouse clickhouse-client --query "
SELECT top_level_dir, count()
FROM filesystem.entries
WHERE snapshot_date='2025-12-27'
GROUP BY top_level_dir
ORDER BY count() DESC
"

----------------------------------------
# 8) Compute recursive directory sizes (REQUIRED)
----------------------------------------

# Aggregates child sizes into parent directories
docker compose run --rm importer \
python scripts/compute_recursive_sizes_v2.py 2025-12-27

----------------------------------------
# 9) Generate Voronoi visualization (REQUIRED)
----------------------------------------

docker compose run --rm importer \
python scripts/compute_voronoi_unified.py 2025-12-27

----------------------------------------
# 10) Optimize tables (recommended)
----------------------------------------

docker compose exec clickhouse clickhouse-client --query \
"OPTIMIZE TABLE filesystem.directory_hierarchy FINAL"

----------------------------------------
# 11) Verify Voronoi data
----------------------------------------

docker compose exec clickhouse clickhouse-client --query "
SELECT name, size, depth
FROM filesystem.voronoi_precomputed
WHERE snapshot_date='2025-12-27'
ORDER BY size DESC
LIMIT 10
"

----------------------------------------
# 12) Start API and Web Dashboard
----------------------------------------

docker compose up -d api web

# Verify
docker compose ps

----------------------------------------
# 13) Open the dashboard
----------------------------------------

# From your local browser:
http://<PUBLIC_IP>:3000

# You should see:
# - Snapshot selector
# - All top-level directories
# - Full Voronoi visualization
